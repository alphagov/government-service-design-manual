---
layout: detailed-guidance
title: Awarding the standard
subtitle: Services so good that people prefer to use them
audience:
  primary: service-manager
  secondary: 
theme: getting-started
category: dbd
status: draft
breadcrumbs:
  -
    title: Home
    url: /service-manual
  -
    title: Digital by Default Service Standard
    url: /service-manual/digital-by-default
---


## Awarding the standard

The process by which services achieve and keep the standard is intended to maximise knowledge sharing, ensure fair and consistent assessment, and avoid ‘one size fits all’ tickbox-style exercises.

In order to achieve the standard and have their service launched on GOV.UK, the responsible service manager will ultimately have to prove their service meets the [criteria of the standard](/service-manual/digital-by-default) to the unanimous satisfaction of a Go Live panel including experts from within and outside government. The panel will apply common sense and a degree of flexibility to their assessments. However, all services within the [scope of the standard](/service-manual/digital-by-default/scope-of-the-standard.html) will be assessed against the same set of criteria.

The Go Live panel will make their assessment on the basis of the [written evidence contained in the service’s public blog](/service-manual/digital-by-default/providing-evidence.html), which is a regularly updated record of how the service has been designed and built, and a live demonstration of the public beta service. 

The department or agency that owns the service is formally responsible for ensuring it achieves and maintains the standard, irrespective of whether it is designed, built and operated by in-house, external or mixed teams. 

### Assessment throughout development

For complex services, we expect the process will take around 18 months to two years. that said, there are no fixed deadlines for how long it should take a service to reach the standard. Having feedback throughout the process is really important, as it should reduce the risk of lengthy projects going off-track. To enable this and support an agile approach to design, progress against the standard will be monitored as part of existing spending control processes. 

Departments currently need [Cabinet Office approval for digital spending](). To simplify this process, a dedicated account manager will work with each department in order to help prioritise their projects.

When a department makes a submission to their account manager for spending approval on services that fall within the [scope of the standard](/service-manual/digital-by-default/scope-of-the-standard.html), GDS will assess whether the work completed so far is in line with it. If the service redesign or build process is at an early stage, GDS will make approval conditional on the proposed service being built to meet the standard. If the service redesign or build process is at a more advanced stage, GDS will make recommendations for additional spending on the basis of the evidence available for a service being on track to meet the standard. [This evidence will be taken from the team’s public blog](/service-manual/digital-by-default/providing-evidence.html). GDS will also explicitly state when the team should return for further approval.

The point of having multiple loops through this process is to effectively support an iterative approach to service design. Relying on the public blog for evidence of progress removes the need for additional paperwork. It will also provide departments with targeted support and feedback on whether they are on track to meet the standard far in advance of a Go Live panel, in order to take any corrective actions earlier. The number of loops a project will go through will vary, though GDS will seek to minimise wherever possible. GDS is currently working with HM Treasury and the Major Projects Authority to ensure current approval and assurance processes are better adapted for digital projects.

## Go Live panel

A Go Live panel will make the final decision on whether a service should be awarded the standard and be launched. The panel will convene within 2-3 weeks of a request being made by the responsible service manager. It will be chaired by GDS, and include a Digital Leader and a service manager (not from the presenting department) on the panel. It will also include other independent experts if suitable and available. Other Digital Leaders and service managers will be free to attend as observers.

The panel will ask questions about the service itself and the evidence set out in the team’s public record. At the conclusion of the meeting, the panel will:


- **Approve:** The service should be awarded the standard, and is ready to be launched on GOV.UK.
- **Resubmit:** The service is nearly ready, but there are some outstanding evidence gaps. The panel will agree a date to reconvene (ideally within 3 weeks) to consider new evidence or updates.
- **Reject:** The service is unable to demonstrate evidence for criteria seen as essential by the panel.

## Failing to meet the standard

A service may fail to meet the standard at three points:


1. during the service’s design, prior to going live
2. rejection at a Go Live panel
3. a live service falling below the performance targets approved at launch

### i. Failure during service design

If there is evidence that a service is being designed in a way which is not in line with the standard, or there is [no public written record of progress](/service-manual/digital-by-default/providing-evidence.html), GDS will raise the issue with the responsible service manager and Digital Leader and suggest corrective action.

Service progress towards meeting the standard will also be assessed at every spending control point the service passes through. If the department cannot provide sufficient evidence that the work completed so far is in line with the criteria and evidence requirements of the standard, further spending on the project will not be approved. If the business case is rejected, GDS will stipulate what the service must provide evidence for in order for funding to be released.

### ii. Failure to pass the Go Live Panel

If the Go Live panel does not produce unanimous approval, the service will not be awarded the standard. If the panel does not award the standard, the Chair will provide feedback to the service manager and Digital Leader on what needs to be rectified. The service manager and Digital Leader will then be invited back to present a second time to the panel on an agreed date. If the panel’s verdict demanded relatively minor changes or a small amount of additional evidence, this second assessment can be completed through correspondence. For more significant changes, a second meeting will be convened.

If the service fails to pass the Go Live panel on two occasions, the Cabinet Office will write to the responsible Minister explaining why the service has not yet been awarded the standard, and what remedial actions are required.

### iii. Failure of a live service to meet performance goals

If performance levels consistently fall below those set out in the evidence presented to the Go Live panel over a 3 month period after a service has gone live, GDS will a) request a note from the service manager which gives evidence against the criteria above, and b) convene a Performance Panel.

The Performance Panel will be chaired by GDS and include representatives from other departments and external experts when suitable and available. The responsible service manager and Digital Leader will present to the panel, explaining why they believe performance levels are below levels expected at launch and set out what remedial actions they intend on taking to rectify the issues within the next 3 months. The panel will approve this plan, or suggest additional actions. It will approve changes to the performance targets set at launch only if there is compelling evidence that the user needs have demonstrably changed. It will also request monthly updates against the actions.

If after a further three months the performance issues still persist, the Cabinet Office will write to the Minister responsible for the service, explaining that the service is failing to meet the standard, and that a ‘health warning’ will be placed on the start page of the transaction explicitly stating that the service does not meet the standard, apologising to users, and requesting their feedback. Once performance returns to the levels expected and agreed at launch, this warning will be removed.  If there is still no improvement a month after this point, GDS will recommend whether the service should be taken offline, and rolled back to a contingency that does not incur significant unintended expense for the taxpayer.

[Include diagram? Make it better?]
