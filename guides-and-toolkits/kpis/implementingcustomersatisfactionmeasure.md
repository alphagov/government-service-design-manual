---
layout: gsdm
title: Implementing user satisfaction
section: guidance
subsection: KPIs
status: draft
---
    
#Implementing user satisfaction
This guidance covers implementing the user satisfaction KPI, including what to do, when to do it and how frequently to measure. Please refer to [Defining KPIs](/guides-and-toolkits/kpis/definingkpis.html) for a definition of user satisfaction.

##Guidance/Tool
<table>
<tr><th></th><th>Inception</th><th>Alpha</th><th>Beta</th><th>Live</th></tr>
<tr><td>Must</td><td>Set user satisfaction as a KPI and benchmark the existing service for future comparison</td><td>Benchmark user satisfaction via remote usability testing and/or a satisfaction survey</td><td>Measure user satisfaction via remote usability testing and/or satisfaction survey</td><td>Measure user satisfaction continually and monitor results on at least a monthly basis</td></tr>
<tr><td>Should</td><td>Develop a plan to measure user satisfaction throughout product development</td><td></td><td>Identify why people are dissatisfied or not completing transactions and take steps to improve</td><td>Carry out a more comprehensive user demographics, usage and attitudes survey every six months</td></tr>
<tr><td>May</td><td></td><td></td><td></td><td>Do drivers analysis to understand what is driving satisfaction for users</td></tr>
</table>

##How frequently should I measure user satisfaction?
An initial measure of user satisfaction must be taken during alpha testing to establish a benchmark. A further measure should be taken during beta testing and ideally will be above 80%. If user satisfaction is less than 80%, the service manager will need to develop a plan to achieve this level within six months of launch. The service will not necessarily be prevented from launching if such a plan is in place.

##What level of user satisfaction should I aim for?
You should plan to reach a minimum level of user satisfaction of 80% within six months of launch. If you have not reached this level prior to launch, you must develop a plan including:
* Results of previous surveys
* Actions based on the results of previous surveys and testing (e.g usability testing)
* Timelines setting out when the actions will be taken

##What about post launch?
You should run a survey continuously, and report satisfaction on a monthly basis. The results should be fed into the development of the service, for example analysis of reasons for dissatisfaction. You should also carry out a more comprehensive user satisfaction survey every six months.

You could also consider doing a drivers analysis of the key factors driving satisfaction with the service. For example, by asking additional questions (e.g. on ease of use, accuracy, look and feel) you can determine which of those factors is most positively contributing to user satisfaction and hence prioritise where to focus ongoing design efforts.

## Further reading
[Survey design](/handbook/160)
